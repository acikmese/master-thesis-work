{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_full_data(data, row_size=None, column_size=None, col_width=-1):\n",
    "    \"\"\"Shows all rows and columns instead of showing only some part and hiding other parts for large data.\n",
    "    \"\"\"\n",
    "    with pd.option_context('display.max_rows', row_size, 'display.max_columns', column_size, 'display.max_colwidth', col_width):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All User IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_list(loc):\n",
    "    # Collecting all student codes from activity folder (which represents all students)\n",
    "    user_codes = []\n",
    "    for x in sorted(os.listdir(loc + 'sensing/activity/')):\n",
    "        # Chooses the string before \".\" and after \"_\"\n",
    "        user_codes.append(x.split('.')[0].split('_')[1])\n",
    "    return user_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity(user, loc):\n",
    "    activity = pd.read_csv(loc + 'sensing/activity/activity_' + user + '.csv')\n",
    "    activity.columns = ['timestamp', 'activity_inference']\n",
    "    # make timestamp unique and take the mode for different values of activity inference\n",
    "    activity = activity.groupby(\"timestamp\")['activity_inference'].apply(lambda x: x.mode()[0]).reset_index()\n",
    "    activity.timestamp = pd.to_datetime(activity.timestamp, unit='s')\n",
    "    activity = activity.set_index('timestamp')\n",
    "    activity = activity.asfreq('s', method='bfill')\n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(user, loc):\n",
    "    audio = pd.read_csv(loc + 'sensing/audio/audio_' + user + '.csv')\n",
    "    audio.columns = ['timestamp', 'audio_inference']\n",
    "    # make timestamp unique and take the mode for different values of audio inference\n",
    "    audio = audio.groupby(\"timestamp\")['audio_inference'].apply(lambda x: x.mode()[0]).reset_index()\n",
    "    audio.timestamp = pd.to_datetime(audio.timestamp, unit='s')\n",
    "    audio = audio.set_index('timestamp')\n",
    "    audio = audio.asfreq('s', method='bfill')\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(user, loc):\n",
    "    conversation = pd.read_csv(loc + 'sensing/conversation/conversation_' + user + '.csv')\n",
    "    conversation.columns = ['start_timestamp', 'end_timestamp']\n",
    "    conversation.start_timestamp = pd.to_datetime(conversation.start_timestamp, unit='s')\n",
    "    conversation.end_timestamp = pd.to_datetime(conversation.end_timestamp, unit='s')\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bluetooth(user, loc):\n",
    "    bluetooth = pd.read_csv(loc + 'sensing/bluetooth/bt_' + user + '.csv', index_col=False)\n",
    "    bluetooth.time = pd.to_datetime(bluetooth.time, unit='s')\n",
    "    return bluetooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wifi(user, loc):\n",
    "    wifi = pd.read_csv(loc + 'sensing/wifi/wifi_' + user + '.csv', index_col=False)\n",
    "    wifi.time = pd.to_datetime(wifi.time, unit='s')\n",
    "    return wifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wifi_loc(user, loc):\n",
    "    wifi_loc = pd.read_csv(loc + 'sensing/wifi_location/wifi_location_' + user + '.csv', index_col=False)\n",
    "    wifi_loc.time = pd.to_datetime(wifi_loc.time, unit='s')\n",
    "    return wifi_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dark(user, loc):\n",
    "    dark = pd.read_csv(loc + 'sensing/dark/dark_' + user + '.csv', index_col=False)\n",
    "    dark.start = pd.to_datetime(dark.start, unit='s')\n",
    "    dark.end = pd.to_datetime(dark.end, unit='s')\n",
    "    return dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phone_charge(user, loc):\n",
    "    phonecharge = pd.read_csv(loc + 'sensing/phonecharge/phonecharge_' + user + '.csv', index_col=False)\n",
    "    phonecharge.start = pd.to_datetime(phonecharge.start, unit='s')\n",
    "    phonecharge.end = pd.to_datetime(phonecharge.end, unit='s')\n",
    "    return phonecharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phone_lock(user, loc):\n",
    "    phonelock = pd.read_csv(loc + 'sensing/phonelock/phonelock_' + user + '.csv', index_col=False)\n",
    "    phonelock.start = pd.to_datetime(phonelock.start, unit='s')\n",
    "    phonelock.end = pd.to_datetime(phonelock.end, unit='s')\n",
    "    return phonelock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sms(user, loc):\n",
    "    sms = pd.read_csv(loc + 'sms/sms_' + user + '.csv', index_col=False)\n",
    "    sms = sms[['timestamp']]\n",
    "    sms = sms.groupby('timestamp').count().reset_index()\n",
    "    sms['timestamp'] = pd.to_datetime(sms.timestamp, unit='s')\n",
    "    sms['sms'] = 1\n",
    "    sms = sms.set_index('timestamp')\n",
    "    return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cal_log(user, loc):\n",
    "    call_log = pd.read_csv(loc + 'call_log/call_log_' + user + '.csv', index_col=False)\n",
    "    if 'CALLS_date' not in call_log.columns:\n",
    "        call_log = call_log[['timestamp']]\n",
    "        call_log = call_log.groupby('timestamp').count().reset_index()\n",
    "        call_log['timestamp'] = pd.to_datetime(call_log.timestamp, unit='s')\n",
    "        call_log['call_log'] = 1\n",
    "        call_log = call_log.set_index('timestamp')\n",
    "    else:\n",
    "        call_log['timestamp'] = pd.to_datetime(call_log.timestamp, unit='s')\n",
    "        call_log['CALLS_date'] = pd.to_datetime(call_log.CALLS_date, unit='ms')\n",
    "        call_log = call_log[['timestamp', 'CALLS_date', 'CALLS_duration']]\n",
    "        call_log = call_log.groupby(['timestamp', 'CALLS_date']).sum().reset_index()\n",
    "        call_log['call_log'] = 1\n",
    "    return call_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One time call this because it includes all of the users' deadlines.\n",
    "def get_deadlines(loc):\n",
    "    deadlines = pd.read_csv(loc + 'education/deadlines.csv', index_col=False)\n",
    "    deadlines = deadlines.T\n",
    "    deadlines.columns = deadlines.iloc[0, :]\n",
    "    deadlines = deadlines.drop(deadlines.index[0])\n",
    "    deadlines.index = pd.to_datetime(deadlines.index)\n",
    "    return deadlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_usage(user, loc):\n",
    "    app = pd.read_csv(loc + 'app_usage/running_app_' + user + '.csv', index_col=False)\n",
    "    app = app[['timestamp', 'RUNNING_TASKS_numRunning']]\n",
    "    app = app.groupby('timestamp').sum().reset_index()\n",
    "    app['timestamp'] = pd.to_datetime(app.timestamp, unit='s')\n",
    "    app.columns = ['timestamp', 'running_apps']\n",
    "    app = app.set_index('timestamp')\n",
    "    return app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merger Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity is the main dataframe, all other data are merged on it.\n",
    "# In this case, df = activity.\n",
    "def merge_audio(df, audio):\n",
    "    df = pd.merge(df, audio, left_index=True, right_index=True, how='outer')\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_conversation(df, conversation):\n",
    "    # add conversation\n",
    "    df['conversation'] = np.nan\n",
    "    for i in range(conversation.shape[0]):\n",
    "        start = conversation.iloc[i, 0]\n",
    "        end = conversation.iloc[i, 1]\n",
    "        df.loc[(df['timestamp'] >= start) & (df['timestamp'] <= end), 'conversation'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bluetooth(df, bluetooth):\n",
    "    # add bluetooth\n",
    "    bluetooth_new = pd.DataFrame()\n",
    "    for time in bluetooth.time.unique():\n",
    "        data = {'timestamp': time}\n",
    "        item = bluetooth[bluetooth.time == time]\n",
    "        data['total_devices_around'] = item.shape[0]\n",
    "        data['total_nearer'] = item[(item.level >= -65) & (item.level <= 0)].shape[0]\n",
    "        data['total_near'] = item[(item.level >= -80) & (item.level < -65)].shape[0]\n",
    "        data['total_far'] = item[(item.level >= -90) & (item.level < -80)].shape[0]\n",
    "        data['total_farther'] = item[(item.level >= -125) & (item.level < -90)].shape[0] # Normally -100 is max but for one anomaly.\n",
    "        data['level_avg'] = round(item.level.mean())\n",
    "        data['level_std'] = item.level.std()\n",
    "        bluetooth_new = bluetooth_new.append(data, ignore_index=True)\n",
    "    bluetooth_new.columns = ['bt_' + i for i in bluetooth_new.columns]\n",
    "    df = pd.merge(df, bluetooth_new, left_on='timestamp', right_on='bt_timestamp', how='outer')\n",
    "    df.drop(columns=['bt_timestamp'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wifi(df, wifi):\n",
    "    # add wifi\n",
    "    wifi_new = pd.DataFrame()\n",
    "    for time in wifi.time.unique():\n",
    "        data = {'timestamp': time}\n",
    "        item = wifi[wifi.time == time]\n",
    "        data['total_devices_around'] = item.shape[0]\n",
    "        data['total_nearer'] = item[item.level >= -60].shape[0]\n",
    "        data['total_near'] = item[(item.level >= -80) & (item.level < -60)].shape[0]\n",
    "        data['total_far'] = item[(item.level >= -100) & (item.level < -80)].shape[0]\n",
    "        data['level_avg'] = round(item.level.mean())\n",
    "        data['level_std'] = item.level.std()\n",
    "        wifi_new = wifi_new.append(data, ignore_index=True)\n",
    "    wifi_new.columns = ['wifi_' + i for i in wifi_new.columns]\n",
    "    df = pd.merge(df, wifi_new, left_on='timestamp', right_on='wifi_timestamp', how='left')\n",
    "    df.drop(columns=['wifi_timestamp'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dark(df, dark):\n",
    "    # add dark\n",
    "    df['phone_in_dark'] = np.nan\n",
    "    for i in range(dark.shape[0]):\n",
    "        start = dark.iloc[i, 0]\n",
    "        end = dark.iloc[i, 1]\n",
    "        df.loc[(df['timestamp'] >= start) & (df['timestamp'] <= end), 'phone_in_dark'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phone_charge(df, phone_charge):\n",
    "    # phone charge\n",
    "    df['phone_charging'] = np.nan\n",
    "    for i in range(phone_charge.shape[0]):\n",
    "        start = phone_charge.iloc[i, 0]\n",
    "        end = phone_charge.iloc[i, 1]\n",
    "        df.loc[(df['timestamp'] >= start) & (df['timestamp'] <= end), 'phone_charging'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phone_lock(df, phone_lock):\n",
    "    # phone locked\n",
    "    df['phone_locked'] = np.nan\n",
    "    for i in range(phone_lock.shape[0]):\n",
    "        start = phone_lock.iloc[i, 0]\n",
    "        end = phone_lock.iloc[i, 1]\n",
    "        df.loc[(df['timestamp'] >= start) & (df['timestamp'] <= end), 'phone_locked'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Sensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sms(df, sms):\n",
    "    df = pd.merge_asof(df, sms, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_call_log(df, call_log):\n",
    "    if 'CALLS_date' in call_log.columns:\n",
    "        only_time = call_log[['timestamp', 'call_log']]\n",
    "        only_time = only_time.set_index('timestamp')\n",
    "        df = pd.merge_asof(df, only_time, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "        call_dur = call_log[['CALLS_date', 'CALLS_duration']]\n",
    "        call_dur.columns = ['CALLS_date', 'call_duration']\n",
    "        call_dur = call_dur.set_index('CALLS_date')\n",
    "        df = pd.merge_asof(df, call_dur, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "        df.loc[df.call_duration.notnull(), 'call_log'] = 1\n",
    "    else:\n",
    "        df = pd.merge_asof(df, call_log, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_deadlines(df, deadlines, user):\n",
    "    if user in deadlines.columns:\n",
    "        user_deadlines = deadlines[user]\n",
    "        for i in range(user_deadlines.shape[0]):\n",
    "            df.loc[(df.index.month==user_deadlines.index[i].month) &\n",
    "                   (df.index.day==user_deadlines.index[i].day), \n",
    "                   'deadlines'] = deadlines[user][i]\n",
    "    else:\n",
    "        df['deadlines'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_app_usage(df, app_usage): # This is same with merge_sms but for understanding.\n",
    "    df = pd.merge_asof(df, app_usage, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use all mergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(user, activity, audio, conversation, bluetooth, wifi, dark, phone_charge, phone_lock, sms, deadlines):\n",
    "    df = merge_audio(activity, audio)\n",
    "    print('audio merge completed.')\n",
    "    df = merge_conversation(df, conversation)\n",
    "    print('conversation merge completed.')\n",
    "    df = merge_bluetooth(df, bluetooth)\n",
    "    print('bluetooth merge completed.')\n",
    "    df = merge_wifi(df, wifi)\n",
    "    print('wifi merge completed.')\n",
    "    df = merge_dark(df, dark)\n",
    "    print('dark merge completed.')\n",
    "    df = merge_phone_charge(df, phone_charge)\n",
    "    print('phone_charge merge completed.')\n",
    "    df = merge_phone_lock(df, phone_lock)\n",
    "    print('phone_lock merge completed.')\n",
    "    df = merge_sms(df, sms)\n",
    "    print('sms merge completed.')\n",
    "    df = merge_call_log(df, call_log)\n",
    "    print('call_log merge completed')\n",
    "    df = merge_deadlines(df, deadlines, user)\n",
    "    print('deadlines merge completed')\n",
    "    df = merge_app_usage(df, app_usage)\n",
    "    print('app_usage merge completed')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(user, typ, cols, loc):\n",
    "    data = pd.read_json(loc + 'EMA/response/' + typ + '/' + typ + '_' + user + '.json')\n",
    "    if 'null' in data.columns:\n",
    "        data = data.drop(columns='null')\n",
    "    if 'location' in data.columns:\n",
    "        data = data.drop(columns='location')\n",
    "    # Checks if the given columns exists in data, if exists drop them.\n",
    "    dr = True \n",
    "    for j in cols:\n",
    "        if j not in data.columns:\n",
    "            dr = False\n",
    "    if dr == True:\n",
    "        data = data.dropna(subset=cols)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_generator(stress, mood2, resample_factor):\n",
    "    stress['level'] = stress['level'].replace([1,2,3], 1)\n",
    "    stress['level'] = stress['level'].replace([4,5], 0)\n",
    "    stress.columns = ['STRESSED', 'resp_time']\n",
    "    mood2 = mood2.replace([1, 3], 0)\n",
    "    mood2 = mood2.replace([2], 1)\n",
    "    mood2.columns = ['STRESSED', 'resp_time']\n",
    "    labels = stress.append(mood2)\n",
    "    labels = labels.sort_values(by='resp_time', ascending=True)\n",
    "    labels = labels.set_index('resp_time').resample(resample_factor).max()\n",
    "    labels = labels[labels.STRESSED.notnull()]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_aggregations(columns):\n",
    "    # Function to assign aggregation method during resampling\n",
    "    agg_dict = {}\n",
    "    for i in columns:\n",
    "        if ('conversation' in i) | ('phone' in i) | ('inference' in i):\n",
    "            agg_dict[i] = np.sum\n",
    "        elif 'level' in i:\n",
    "            agg_dict[i] = np.mean\n",
    "        elif 'total' in i:\n",
    "            agg_dict[i] = np.max\n",
    "    return agg_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset directory\n",
    "dir_loc = '../../student-life-study-data/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user list\n",
    "user_codes = get_user_list(dir_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVE AFTER TEST\n",
    "user_codes = user_codes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataset\n",
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVE\n",
    "user = user_codes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity data read for u00 is completed.\n",
      "audio data read for u00 is completed.\n",
      "conversation data read for u00 is completed.\n",
      "bluetooth data read for u00 is completed.\n",
      "wifi data read for u00 is completed.\n",
      "dark data read for u00 is completed.\n",
      "phone_charge data read for u00 is completed.\n",
      "phone_lock data read for u00 is completed.\n",
      "stress data read for u00 is completed.\n",
      "mood2 data read for u00 is completed.\n"
     ]
    }
   ],
   "source": [
    "deadlines = get_deadlines(dir_loc)\n",
    "\n",
    "# Sensing\n",
    "activity = get_activity(user, dir_loc)\n",
    "print('activity data read for', user, 'is completed.')\n",
    "audio = get_audio(user, dir_loc)\n",
    "print('audio data read for', user, 'is completed.')\n",
    "conversation = get_conversation(user, dir_loc)\n",
    "print('conversation data read for', user, 'is completed.')\n",
    "bluetooth = get_bluetooth(user, dir_loc)\n",
    "print('bluetooth data read for', user, 'is completed.')\n",
    "wifi = get_wifi(user, dir_loc)\n",
    "print('wifi data read for', user, 'is completed.')\n",
    "dark = get_dark(user, dir_loc)\n",
    "print('dark data read for', user, 'is completed.')\n",
    "phone_charge = get_phone_charge(user, dir_loc)\n",
    "print('phone_charge data read for', user, 'is completed.')\n",
    "phone_lock = get_phone_lock(user, dir_loc)\n",
    "print('phone_lock data read for', user, 'is completed.')\n",
    "\n",
    "# Not Sensing\n",
    "sms = get_sms(user, dir_loc)\n",
    "print('sms data read for', user, 'is completed.')\n",
    "call_log = get_call_log(user, dir_loc)\n",
    "print('call_log data read for', user, 'is completed.')\n",
    "app_usage = get_app_usage(user, dir_loc)\n",
    "print('app_usage data read for', user, 'is completed.')\n",
    "\n",
    "# EMA\n",
    "stress = ema(user, 'Stress', ['level'], dir_loc)\n",
    "print('stress data read for', user, 'is completed.')\n",
    "mood2 = ema(user, 'Mood 2', ['how'], dir_loc)\n",
    "print('mood2 data read for', user, 'is completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio merge completed.\n",
      "conversation merge completed.\n",
      "bluetooth merge completed.\n",
      "wifi merge completed.\n",
      "dark merge completed.\n",
      "phone_charge merge completed.\n",
      "phone_lock merge completed.\n"
     ]
    }
   ],
   "source": [
    "df = merge_all(activity, audio, conversation,\n",
    "                bluetooth, wifi, dark,\n",
    "                phone_charge, phone_lock,\n",
    "               sms, call_log, deadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "if stress.shape[1] == 2:\n",
    "    stress['level'] = stress['level'].replace([1,2,3], 1)\n",
    "    stress['level'] = stress['level'].replace([4,5], 0)\n",
    "    stress.columns = ['STRESSED', 'resp_time']\n",
    "\n",
    "if mood2.shape[1] == 2:\n",
    "    mood2 = mood2.replace([1, 3], 0)\n",
    "    mood2 = mood2.replace([2], 1)\n",
    "    mood2.columns = ['STRESSED', 'resp_time']\n",
    "\n",
    "labels = stress.append(mood2)\n",
    "labels = labels.sort_values(by='resp_time', ascending=True)\n",
    "labels = labels.set_index('resp_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only valid timestamps\n",
    "df_backup = df[df.timestamp.notnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.timestamp.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty values in dataset.\n",
    "df.loc[:, ['activity_inference',\n",
    "           'audio_inference']] = df.loc[:, ['activity_inference',\n",
    "                                             'audio_inference']].fillna(value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['conversation',\n",
    "            'phone_in_dark',\n",
    "            'phone_charging',\n",
    "            'phone_locked',\n",
    "            'sms',\n",
    "            'call_log']] = df.loc[:, ['conversation',\n",
    "                                        'phone_in_dark',\n",
    "                                        'phone_charging',\n",
    "                                        'phone_locked',\n",
    "                                        'sms',\n",
    "                                        'call_log']].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['activity_inference', \n",
    "           'audio_inference']] = df.loc[:, ['activity_inference', \n",
    "                                            'audio_inference']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "df['activity_inference'] = df['activity_inference'].astype('category')\n",
    "df['audio_inference'] = df['audio_inference'].astype('category')\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling\n",
    "df = df.set_index('timestamp')\n",
    "df.index = pd.to_datetime(df.index, unit='s')\n",
    "\n",
    "res_aggs = resample_aggregations(list(df.columns))\n",
    "df = df.resample('10min').agg(res_aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df and labels\n",
    "df = pd.merge_asof(df, labels, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 26)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.STRESSED.notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-741c23a2481b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Sensing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mactivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbluetooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bluetooth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d1e275c6881e>\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m(user, loc)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio_inference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# make timestamp unique and take the mode for different values of audio inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_inference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m                       examples=_apply_docs['series_examples']))\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     @Substitution(see_also=_agg_see_also_doc,\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.chained_assignment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         keys, values, mutated = self.grouper.apply(f, self._selected_obj,\n\u001b[0;32m--> 707\u001b[0;31m                                                    self.axis)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d1e275c6881e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio_inference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# make timestamp unique and take the mode for different values of audio inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_inference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(self, dropna)\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \"\"\"\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# TODO: Add option for bins like value_counts()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(values, dropna)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to sort modes: {error}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_reconstruct_data\u001b[0;34m(values, dtype, original)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \"\"\"\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_array_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m     return (isinstance(dtype, ExtensionDtype) or\n\u001b[0;32m-> 1749\u001b[0;31m             registry.find(dtype) is not None)\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdtype_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mdtype_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deadlines = get_deadlines(dir_loc)\n",
    "\n",
    "for user in user_codes:\n",
    "    # Sensing\n",
    "    activity = get_activity(user, dir_loc)\n",
    "    print('activity data read for', user, 'is completed.')\n",
    "    audio = get_audio(user, dir_loc)\n",
    "    print('audio data read for', user, 'is completed.')\n",
    "    conversation = get_conversation(user, dir_loc)\n",
    "    print('conversation data read for', user, 'is completed.')\n",
    "    bluetooth = get_bluetooth(user, dir_loc)\n",
    "    print('bluetooth data read for', user, 'is completed.')\n",
    "    wifi = get_wifi(user, dir_loc)\n",
    "    print('wifi data read for', user, 'is completed.')\n",
    "    dark = get_dark(user, dir_loc)\n",
    "    print('dark data read for', user, 'is completed.')\n",
    "    phone_charge = get_phone_charge(user, dir_loc)\n",
    "    print('phone_charge data read for', user, 'is completed.')\n",
    "    phone_lock = get_phone_lock(user, dir_loc)\n",
    "    print('phone_lock data read for', user, 'is completed.')\n",
    "    \n",
    "    # Other Than Sensing\n",
    "    sms = get_sms(user, dir_loc)\n",
    "    print('sms data read for', user, 'is completed.')\n",
    "    call_log = get_call_log(user, dir_loc)\n",
    "    print('call_log data read for', user, 'is completed.')\n",
    "    app_usage = get_app_usage(user, dir_loc)\n",
    "    print('app_usage data read for', user, 'is completed.')\n",
    "    \n",
    "    # EMA\n",
    "    stress = ema(user, 'Stress', ['level'], dir_loc)\n",
    "    print('stress data read for', user, 'is completed.')\n",
    "    mood2 = ema(user, 'Mood 2', ['how'], dir_loc)\n",
    "    print('mood2 data read for', user, 'is completed.')\n",
    "\n",
    "    print('DATA READ IS COMPLETED.')\n",
    "\n",
    "    df = merge_all(user, activity, audio, conversation,\n",
    "                    bluetooth, wifi, dark,\n",
    "                    phone_charge, phone_lock,\n",
    "                   sms, call_log, deadlines, app_usage)\n",
    "\n",
    "    print('Shape of df after merge:', str(df.shape))\n",
    "    print('Data merge is completed.')\n",
    "\n",
    "    # Create labels\n",
    "    if stress.shape[1] == 2:\n",
    "        stress['level'] = stress['level'].replace([1,2,3], 1)\n",
    "        stress['level'] = stress['level'].replace([4,5], 0)\n",
    "        stress.columns = ['STRESSED', 'resp_time']\n",
    "\n",
    "    if mood2.shape[1] == 2:\n",
    "        mood2 = mood2.replace([1, 3], 0)\n",
    "        mood2 = mood2.replace([2], 1)\n",
    "        mood2.columns = ['STRESSED', 'resp_time']\n",
    "\n",
    "    labels = stress.append(mood2)\n",
    "    labels = labels.sort_values(by='resp_time', ascending=True)\n",
    "    labels = labels.set_index('resp_time')\n",
    "\n",
    "\n",
    "    # Choose only valid timestamps\n",
    "    df = df[df.timestamp.notnull()]\n",
    "\n",
    "    # Fill empty values in dataset.\n",
    "    df.loc[:, ['activity_inference',\n",
    "               'audio_inference']] = df.loc[:, ['activity_inference',\n",
    "                                                 'audio_inference']].fillna(value=3)\n",
    "\n",
    "    df.loc[:, ['conversation',\n",
    "                'phone_in_dark',\n",
    "                'phone_charging',\n",
    "                'phone_locked',\n",
    "                'sms',\n",
    "                'call_log']] = df.loc[:, ['conversation',\n",
    "                                        'phone_in_dark',\n",
    "                                        'phone_charging',\n",
    "                                        'phone_locked',\n",
    "                                        'sms',\n",
    "                                        'call_log']].fillna(value=0)\n",
    "\n",
    "    df.loc[:, ['activity_inference', \n",
    "               'audio_inference']] = df.loc[:, ['activity_inference', \n",
    "                                                'audio_inference']].astype(int)\n",
    "\n",
    "    # One Hot Encode\n",
    "    df['activity_inference'] = df['activity_inference'].astype('category')\n",
    "    df['audio_inference'] = df['audio_inference'].astype('category')\n",
    "    df = pd.get_dummies(df)\n",
    "\n",
    "    # Resampling\n",
    "    df = df.set_index('timestamp')\n",
    "    df.index = pd.to_datetime(df.index, unit='s')\n",
    "\n",
    "    res_aggs = resample_aggregations(list(df.columns))\n",
    "    df = df.resample('10min').agg(res_aggs)\n",
    "\n",
    "    # Merge df and labels\n",
    "    df = pd.merge_asof(df, labels, left_index=True, right_index=True, tolerance=pd.Timedelta('10m'))\n",
    "\n",
    "    df.to_csv('prepared_user_data/' + user + '_sensing_data.csv', index=True, header=True)\n",
    "\n",
    "    print(user, 'is completed.')\n",
    "    print('Shape of df is:', str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_full_data(dataset.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
