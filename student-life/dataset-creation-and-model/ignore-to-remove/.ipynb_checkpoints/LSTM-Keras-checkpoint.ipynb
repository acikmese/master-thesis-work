{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_full_data(data, row_size=None, column_size=None, col_width=-1):\n",
    "    \"\"\"\n",
    "    Shows all rows and columns instead of showing only some part \n",
    "    and hiding other parts for large data.\n",
    "    \"\"\"\n",
    "    with pd.option_context('display.max_rows', row_size, \n",
    "                           'display.max_columns', column_size, \n",
    "                           'display.max_colwidth', col_width):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>conversation</th>\n",
       "      <th>bt_level_avg</th>\n",
       "      <th>bt_level_std</th>\n",
       "      <th>bt_total_devices_around</th>\n",
       "      <th>bt_total_far</th>\n",
       "      <th>bt_total_farther</th>\n",
       "      <th>bt_total_near</th>\n",
       "      <th>bt_total_nearer</th>\n",
       "      <th>wifi_level_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>phone_locked</th>\n",
       "      <th>activity_inference_0</th>\n",
       "      <th>activity_inference_1</th>\n",
       "      <th>activity_inference_2</th>\n",
       "      <th>activity_inference_3</th>\n",
       "      <th>audio_inference_0</th>\n",
       "      <th>audio_inference_1</th>\n",
       "      <th>audio_inference_2</th>\n",
       "      <th>audio_inference_3</th>\n",
       "      <th>STRESSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-27 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-27 04:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-27 04:20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-27 04:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>208.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-27 04:40:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  conversation  bt_level_avg  bt_level_std  \\\n",
       "0  2013-03-27 04:00:00           0.0           NaN           NaN   \n",
       "1  2013-03-27 04:10:00           0.0           NaN           NaN   \n",
       "2  2013-03-27 04:20:00           0.0           NaN           NaN   \n",
       "3  2013-03-27 04:30:00           0.0           NaN           NaN   \n",
       "4  2013-03-27 04:40:00         200.0           NaN           NaN   \n",
       "\n",
       "   bt_total_devices_around  bt_total_far  bt_total_farther  bt_total_near  \\\n",
       "0                      NaN           NaN               NaN            NaN   \n",
       "1                      NaN           NaN               NaN            NaN   \n",
       "2                      NaN           NaN               NaN            NaN   \n",
       "3                      NaN           NaN               NaN            NaN   \n",
       "4                      NaN           NaN               NaN            NaN   \n",
       "\n",
       "   bt_total_nearer  wifi_level_avg  ...  phone_locked  activity_inference_0  \\\n",
       "0              NaN           -77.0  ...           0.0                 599.0   \n",
       "1              NaN             NaN  ...           0.0                 600.0   \n",
       "2              NaN           -71.5  ...           0.0                 600.0   \n",
       "3              NaN             NaN  ...         208.0                 600.0   \n",
       "4              NaN           -62.0  ...         600.0                 600.0   \n",
       "\n",
       "   activity_inference_1  activity_inference_2  activity_inference_3  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   audio_inference_0  audio_inference_1  audio_inference_2  audio_inference_3  \\\n",
       "0              274.0                0.0              185.0              140.0   \n",
       "1              557.0                1.0               42.0                0.0   \n",
       "2              457.0                0.0              143.0                0.0   \n",
       "3              564.0                1.0               35.0                0.0   \n",
       "4              127.0               94.0              379.0                0.0   \n",
       "\n",
       "   STRESSED  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined_samples/combined_data.csv')\n",
    "# Eliminate first unnecessary column.\n",
    "df = df.iloc[:, 1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2347\n"
     ]
    }
   ],
   "source": [
    "# Total number of instances\n",
    "print(df[df.STRESSED.notnull()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe with Same Length Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_same_length_instances(df, length=72, label='STRESSED'):\n",
    "    df = df.drop(columns=['timestamp'])\n",
    "    full_data = pd.DataFrame()\n",
    "    indexes = list(df[df[label].notnull()].index) # Choose label indexes\n",
    "    start = 0\n",
    "    for i in indexes:\n",
    "        if i - start >= length:\n",
    "            # If the length of instance is higher than treshold length,\n",
    "            # It chooses last timestamps (according to given length)\n",
    "            instance = df.iloc[i-length+1:i+1, :]\n",
    "            full_data = full_data.append(instance, ignore_index=True, sort=False)\n",
    "        else:\n",
    "            # If the length of instance is lower than treshold length,\n",
    "            # It chooses all timestamps and add zeros to head timestamps until reach given length.\n",
    "            index_diff = i - start\n",
    "            instance = df.iloc[i-index_diff+1:i+1, :]\n",
    "            back_fill = np.empty((length-index_diff, df.shape[1]))\n",
    "            back_fill.fill(np.nan)\n",
    "            back_fill = pd.DataFrame(back_fill, columns=df.columns)\n",
    "            instance = back_fill.append(instance, ignore_index=True, sort=False)\n",
    "            full_data = full_data.append(instance, ignore_index=True, sort=False)\n",
    "        start = i\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_same = create_same_length_instances(df, length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 2347 \n",
      "\n",
      "Each class size:\n",
      "1.0    1614\n",
      "0.0     733\n",
      "Name: STRESSED, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total sample size:', df_same[df_same.STRESSED.notnull()].shape[0], '\\n')\n",
    "print('Each class size:\\n' + str(df_same.STRESSED.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>bt_level_avg</th>\n",
       "      <th>bt_level_std</th>\n",
       "      <th>bt_total_devices_around</th>\n",
       "      <th>bt_total_far</th>\n",
       "      <th>bt_total_farther</th>\n",
       "      <th>bt_total_near</th>\n",
       "      <th>bt_total_nearer</th>\n",
       "      <th>wifi_level_avg</th>\n",
       "      <th>wifi_level_std</th>\n",
       "      <th>...</th>\n",
       "      <th>phone_locked</th>\n",
       "      <th>activity_inference_0</th>\n",
       "      <th>activity_inference_1</th>\n",
       "      <th>activity_inference_2</th>\n",
       "      <th>activity_inference_3</th>\n",
       "      <th>audio_inference_0</th>\n",
       "      <th>audio_inference_1</th>\n",
       "      <th>audio_inference_2</th>\n",
       "      <th>audio_inference_3</th>\n",
       "      <th>STRESSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>5.618846</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>8.447316</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>569.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>20.126268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     conversation  bt_level_avg  bt_level_std  bt_total_devices_around  \\\n",
       "71            0.0           NaN           NaN                      NaN   \n",
       "143           0.0           NaN           NaN                      NaN   \n",
       "215           0.0         -89.0      5.618846                      7.0   \n",
       "287         569.0           NaN           NaN                      NaN   \n",
       "359         600.0           NaN           NaN                      NaN   \n",
       "\n",
       "     bt_total_far  bt_total_farther  bt_total_near  bt_total_nearer  \\\n",
       "71            NaN               NaN            NaN              NaN   \n",
       "143           NaN               NaN            NaN              NaN   \n",
       "215           3.0               3.0            1.0              0.0   \n",
       "287           NaN               NaN            NaN              NaN   \n",
       "359           NaN               NaN            NaN              NaN   \n",
       "\n",
       "     wifi_level_avg  wifi_level_std  ...  phone_locked  activity_inference_0  \\\n",
       "71            -61.0             NaN  ...           0.0                 600.0   \n",
       "143             NaN             NaN  ...           0.0                 600.0   \n",
       "215           -84.0        8.447316  ...         600.0                 598.0   \n",
       "287             NaN             NaN  ...         600.0                 600.0   \n",
       "359           -76.0       20.126268  ...           0.0                 600.0   \n",
       "\n",
       "     activity_inference_1  activity_inference_2  activity_inference_3  \\\n",
       "71                    0.0                   0.0                   0.0   \n",
       "143                   0.0                   0.0                   0.0   \n",
       "215                   2.0                   0.0                   0.0   \n",
       "287                   0.0                   0.0                   0.0   \n",
       "359                   0.0                   0.0                   0.0   \n",
       "\n",
       "     audio_inference_0  audio_inference_1  audio_inference_2  \\\n",
       "71               595.0                2.0                3.0   \n",
       "143              356.0                2.0              242.0   \n",
       "215              600.0                0.0                0.0   \n",
       "287               49.0              510.0               41.0   \n",
       "359               40.0              536.0               24.0   \n",
       "\n",
       "     audio_inference_3  STRESSED  \n",
       "71                 0.0       1.0  \n",
       "143                0.0       1.0  \n",
       "215                0.0       1.0  \n",
       "287                0.0       1.0  \n",
       "359                0.0       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_same[df_same.STRESSED.notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, label_col='STRESSED'):\n",
    "    features = df_same.drop(columns=label_col)\n",
    "    features_norm = (features - features.mean(axis=0)) / (features.max(axis=0) - features.min(axis=0))\n",
    "    df.loc[:, df.columns != label_col] = features_norm\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>bt_level_avg</th>\n",
       "      <th>bt_level_std</th>\n",
       "      <th>bt_total_devices_around</th>\n",
       "      <th>bt_total_far</th>\n",
       "      <th>bt_total_farther</th>\n",
       "      <th>bt_total_near</th>\n",
       "      <th>bt_total_nearer</th>\n",
       "      <th>wifi_level_avg</th>\n",
       "      <th>wifi_level_std</th>\n",
       "      <th>wifi_total_devices_around</th>\n",
       "      <th>wifi_total_far</th>\n",
       "      <th>wifi_total_near</th>\n",
       "      <th>wifi_total_nearer</th>\n",
       "      <th>phone_in_dark</th>\n",
       "      <th>phone_charging</th>\n",
       "      <th>phone_locked</th>\n",
       "      <th>activity_inference_0</th>\n",
       "      <th>activity_inference_1</th>\n",
       "      <th>activity_inference_2</th>\n",
       "      <th>activity_inference_3</th>\n",
       "      <th>audio_inference_0</th>\n",
       "      <th>audio_inference_1</th>\n",
       "      <th>audio_inference_2</th>\n",
       "      <th>audio_inference_3</th>\n",
       "      <th>STRESSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757211</td>\n",
       "      <td>-0.059292</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.135913</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>-0.014352</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>-0.045424</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>-0.085929</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.237882</td>\n",
       "      <td>0.385415</td>\n",
       "      <td>-0.147496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.745545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.081215</td>\n",
       "      <td>0.243748</td>\n",
       "      <td>-0.162496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435545</td>\n",
       "      <td>-0.059324</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>0.041203</td>\n",
       "      <td>0.053230</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>-0.041241</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>-0.067061</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.587882</td>\n",
       "      <td>0.557082</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.091883</td>\n",
       "      <td>-0.069595</td>\n",
       "      <td>0.331846</td>\n",
       "      <td>0.366901</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>-0.371109</td>\n",
       "      <td>0.414573</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.599548</td>\n",
       "      <td>0.667082</td>\n",
       "      <td>-0.067496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147211</td>\n",
       "      <td>-0.059450</td>\n",
       "      <td>-0.108500</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>-0.069908</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>-0.087937</td>\n",
       "      <td>-0.081701</td>\n",
       "      <td>0.349087</td>\n",
       "      <td>0.423505</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>-0.896109</td>\n",
       "      <td>0.939573</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.236215</td>\n",
       "      <td>0.273748</td>\n",
       "      <td>-0.037496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation  bt_level_avg  bt_level_std  bt_total_devices_around  \\\n",
       "0  0.757211     -0.059292      0.012913      0.135913                  \n",
       "1  0.745545     NaN           NaN           NaN                        \n",
       "2  0.435545     -0.059324      0.057321      0.110913                  \n",
       "3  0.757211     NaN           NaN           NaN                        \n",
       "4  0.147211     -0.059450     -0.108500     -0.014087                  \n",
       "\n",
       "   bt_total_far  bt_total_farther  bt_total_near  bt_total_nearer  \\\n",
       "0  0.065572     -0.014352          0.150004      -0.027515          \n",
       "1 NaN           NaN               NaN            NaN                \n",
       "2  0.065572      0.041203          0.053230       0.034985          \n",
       "3 NaN           NaN               NaN            NaN                \n",
       "4  0.065572     -0.069908         -0.011286      -0.027515          \n",
       "\n",
       "   wifi_level_avg  wifi_level_std  wifi_total_devices_around  wifi_total_far  \\\n",
       "0  0.050303       -0.045424       -0.047465                  -0.085929         \n",
       "1 NaN             NaN             NaN                        NaN               \n",
       "2  0.025127       -0.041241       -0.047465                  -0.067061         \n",
       "3 -0.091883       -0.069595        0.331846                   0.366901         \n",
       "4 -0.087937       -0.081701        0.349087                   0.423505         \n",
       "\n",
       "   wifi_total_near  wifi_total_nearer  phone_in_dark  phone_charging  \\\n",
       "0  0.038959        -0.075923          -0.380118      -0.208148         \n",
       "1 NaN              NaN                -0.380118      -0.208148         \n",
       "2  0.017220        -0.075923          -0.380118      -0.208148         \n",
       "3  0.038959        -0.075923          -0.380118      -0.208148         \n",
       "4  0.017220        -0.075923          -0.380118      -0.208148         \n",
       "\n",
       "   phone_locked  activity_inference_0  activity_inference_1  \\\n",
       "0 -0.479851      0.103891             -0.060427               \n",
       "1 -0.479851      0.103891             -0.060427               \n",
       "2 -0.479851      0.103891             -0.060427               \n",
       "3 -0.479851     -0.371109              0.414573               \n",
       "4 -0.479851     -0.896109              0.939573               \n",
       "\n",
       "   activity_inference_2  activity_inference_3  audio_inference_0  \\\n",
       "0 -0.014357             -0.029072             -0.237882            \n",
       "1 -0.014357             -0.029072             -0.081215            \n",
       "2 -0.014357             -0.029072             -0.587882            \n",
       "3 -0.014357             -0.029072             -0.599548            \n",
       "4 -0.014357             -0.029072             -0.236215            \n",
       "\n",
       "   audio_inference_1  audio_inference_2  audio_inference_3  STRESSED  \n",
       "0  0.385415          -0.147496          -0.000036          NaN        \n",
       "1  0.243748          -0.162496          -0.000036          NaN        \n",
       "2  0.557082           0.030838          -0.000036          NaN        \n",
       "3  0.667082          -0.067496          -0.000036          NaN        \n",
       "4  0.273748          -0.037496          -0.000036          NaN        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm = normalize(df_same)\n",
    "show_full_data(df_norm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 2347 \n",
      "\n",
      "Each class size:\n",
      "1.0    1614\n",
      "0.0     733\n",
      "Name: STRESSED, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Total sample size:', df_norm[df_norm.STRESSED.notnull()].shape[0], '\\n')\n",
    "print('Each class size:\\n' + str(df_norm.STRESSED.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls(df, label_col='STRESSED'):\n",
    "    df.loc[:, df.columns != label_col] = df.loc[:, df.columns != label_col].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>bt_level_avg</th>\n",
       "      <th>bt_level_std</th>\n",
       "      <th>bt_total_devices_around</th>\n",
       "      <th>bt_total_far</th>\n",
       "      <th>bt_total_farther</th>\n",
       "      <th>bt_total_near</th>\n",
       "      <th>bt_total_nearer</th>\n",
       "      <th>wifi_level_avg</th>\n",
       "      <th>wifi_level_std</th>\n",
       "      <th>wifi_total_devices_around</th>\n",
       "      <th>wifi_total_far</th>\n",
       "      <th>wifi_total_near</th>\n",
       "      <th>wifi_total_nearer</th>\n",
       "      <th>phone_in_dark</th>\n",
       "      <th>phone_charging</th>\n",
       "      <th>phone_locked</th>\n",
       "      <th>activity_inference_0</th>\n",
       "      <th>activity_inference_1</th>\n",
       "      <th>activity_inference_2</th>\n",
       "      <th>activity_inference_3</th>\n",
       "      <th>audio_inference_0</th>\n",
       "      <th>audio_inference_1</th>\n",
       "      <th>audio_inference_2</th>\n",
       "      <th>audio_inference_3</th>\n",
       "      <th>STRESSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757211</td>\n",
       "      <td>-0.059292</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.135913</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>-0.014352</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>-0.045424</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>-0.085929</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.237882</td>\n",
       "      <td>0.385415</td>\n",
       "      <td>-0.147496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.745545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.081215</td>\n",
       "      <td>0.243748</td>\n",
       "      <td>-0.162496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.435545</td>\n",
       "      <td>-0.059324</td>\n",
       "      <td>0.057321</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>0.041203</td>\n",
       "      <td>0.053230</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>-0.041241</td>\n",
       "      <td>-0.047465</td>\n",
       "      <td>-0.067061</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.587882</td>\n",
       "      <td>0.557082</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.091883</td>\n",
       "      <td>-0.069595</td>\n",
       "      <td>0.331846</td>\n",
       "      <td>0.366901</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>-0.371109</td>\n",
       "      <td>0.414573</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.599548</td>\n",
       "      <td>0.667082</td>\n",
       "      <td>-0.067496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147211</td>\n",
       "      <td>-0.059450</td>\n",
       "      <td>-0.108500</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>0.065572</td>\n",
       "      <td>-0.069908</td>\n",
       "      <td>-0.011286</td>\n",
       "      <td>-0.027515</td>\n",
       "      <td>-0.087937</td>\n",
       "      <td>-0.081701</td>\n",
       "      <td>0.349087</td>\n",
       "      <td>0.423505</td>\n",
       "      <td>0.017220</td>\n",
       "      <td>-0.075923</td>\n",
       "      <td>-0.380118</td>\n",
       "      <td>-0.208148</td>\n",
       "      <td>-0.479851</td>\n",
       "      <td>-0.896109</td>\n",
       "      <td>0.939573</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.029072</td>\n",
       "      <td>-0.236215</td>\n",
       "      <td>0.273748</td>\n",
       "      <td>-0.037496</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation  bt_level_avg  bt_level_std  bt_total_devices_around  \\\n",
       "0  0.757211     -0.059292      0.012913      0.135913                  \n",
       "1  0.745545      0.000000      0.000000      0.000000                  \n",
       "2  0.435545     -0.059324      0.057321      0.110913                  \n",
       "3  0.757211      0.000000      0.000000      0.000000                  \n",
       "4  0.147211     -0.059450     -0.108500     -0.014087                  \n",
       "\n",
       "   bt_total_far  bt_total_farther  bt_total_near  bt_total_nearer  \\\n",
       "0  0.065572     -0.014352          0.150004      -0.027515          \n",
       "1  0.000000      0.000000          0.000000       0.000000          \n",
       "2  0.065572      0.041203          0.053230       0.034985          \n",
       "3  0.000000      0.000000          0.000000       0.000000          \n",
       "4  0.065572     -0.069908         -0.011286      -0.027515          \n",
       "\n",
       "   wifi_level_avg  wifi_level_std  wifi_total_devices_around  wifi_total_far  \\\n",
       "0  0.050303       -0.045424       -0.047465                  -0.085929         \n",
       "1  0.000000        0.000000        0.000000                   0.000000         \n",
       "2  0.025127       -0.041241       -0.047465                  -0.067061         \n",
       "3 -0.091883       -0.069595        0.331846                   0.366901         \n",
       "4 -0.087937       -0.081701        0.349087                   0.423505         \n",
       "\n",
       "   wifi_total_near  wifi_total_nearer  phone_in_dark  phone_charging  \\\n",
       "0  0.038959        -0.075923          -0.380118      -0.208148         \n",
       "1  0.000000         0.000000          -0.380118      -0.208148         \n",
       "2  0.017220        -0.075923          -0.380118      -0.208148         \n",
       "3  0.038959        -0.075923          -0.380118      -0.208148         \n",
       "4  0.017220        -0.075923          -0.380118      -0.208148         \n",
       "\n",
       "   phone_locked  activity_inference_0  activity_inference_1  \\\n",
       "0 -0.479851      0.103891             -0.060427               \n",
       "1 -0.479851      0.103891             -0.060427               \n",
       "2 -0.479851      0.103891             -0.060427               \n",
       "3 -0.479851     -0.371109              0.414573               \n",
       "4 -0.479851     -0.896109              0.939573               \n",
       "\n",
       "   activity_inference_2  activity_inference_3  audio_inference_0  \\\n",
       "0 -0.014357             -0.029072             -0.237882            \n",
       "1 -0.014357             -0.029072             -0.081215            \n",
       "2 -0.014357             -0.029072             -0.587882            \n",
       "3 -0.014357             -0.029072             -0.599548            \n",
       "4 -0.014357             -0.029072             -0.236215            \n",
       "\n",
       "   audio_inference_1  audio_inference_2  audio_inference_3  STRESSED  \n",
       "0  0.385415          -0.147496          -0.000036          NaN        \n",
       "1  0.243748          -0.162496          -0.000036          NaN        \n",
       "2  0.557082           0.030838          -0.000036          NaN        \n",
       "3  0.667082          -0.067496          -0.000036          NaN        \n",
       "4  0.273748          -0.037496          -0.000036          NaN        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filled = fill_nulls(df_norm)\n",
    "show_full_data(df_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    71,    143,    215,    287,    359,    431,    503,    575,\n",
       "               647,    719,\n",
       "            ...\n",
       "            168335, 168407, 168479, 168551, 168623, 168695, 168767, 168839,\n",
       "            168911, 168983],\n",
       "           dtype='int64', length=2347)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled[df_filled['STRESSED'].notnull()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instances(df, length=72, label='STRESSED'):\n",
    "    # Converts dataframe to tensor instances to feed lstm network.\n",
    "    total_instances = df[df[label].notnull()].shape[0]\n",
    "    total_features = df[df[label].notnull()].shape[1] - 1\n",
    "    indexes = list(df[df[label].notnull()].index)\n",
    "    data = df.drop(columns=[label])\n",
    "    all_data = np.empty(shape=(total_instances, length, total_features))\n",
    "    for instance_no, label_index in enumerate(indexes):\n",
    "        start = label_index - length + 1\n",
    "        all_data[instance_no] = data.iloc[start:label_index+1, :].values\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_instances(df_filled, length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances: 2347\n",
      "One sample's sequence length: 72\n",
      "Feature size: 25\n"
     ]
    }
   ],
   "source": [
    "print('Total number of instances:', X.shape[0])\n",
    "print(\"One sample's sequence length:\", X.shape[1])\n",
    "print(\"Feature size:\", X.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_filled.loc[df_filled['STRESSED'].notnull(), 'STRESSED'].values.reshape(2347,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2347, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Randomly Chosen Train and Test Data with Specific Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_one_indexes = np.where(y == 1)[0]\n",
    "# all_one_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_zero_indexes = np.where(y == 0)[0]\n",
    "# all_zero_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ones = np.random.choice(all_one_indexes, 500, replace=False)\n",
    "# print(ones.shape)\n",
    "# print(np.unique(ones).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeros = np.random.choice(all_zero_indexes, 500, replace=False)\n",
    "# print(zeros.shape)\n",
    "# print(np.unique(zeros).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indexes = np.concatenate((ones, zeros))\n",
    "# print(train_indexes.shape)\n",
    "# print(np.unique(train_indexes).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indexes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(train_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indexes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_x = X[train_indexes, :, :]\n",
    "# new_y = y[train_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_x.shape)\n",
    "# print(new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.where(new_y == 1)[0].shape)\n",
    "# print(np.where(new_y == 0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indexes = np.array([i for i in range(len(y)) if i not in train_indexes])\n",
    "# print(test_indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(list(set(train_indexes) - set(test_indexes))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_used_ones = np.array(list(set(all_one_indexes) - set(ones)))\n",
    "# print(not_used_ones.shape)\n",
    "# print(np.unique(not_used_ones).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(list(set(not_used_ones) - set(train_indexes))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_used_zeros = np.array(list(set(all_zero_indexes) - set(zeros)))\n",
    "# print(not_used_zeros.shape)\n",
    "# print(np.unique(not_used_zeros).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sample_size = min(len(not_used_ones), len(not_used_zeros))\n",
    "# print(test_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ones = np.random.choice(not_used_ones, test_sample_size, replace=False)\n",
    "# print(test_ones.shape)\n",
    "# print(np.unique(test_ones).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_zeros = np.random.choice(not_used_zeros, test_sample_size, replace=False)\n",
    "# print(test_zeros.shape)\n",
    "# print(np.unique(test_zeros).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_indexes = np.concatenate((test_ones, test_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x = X[test_indexes, :, :]\n",
    "# test_y = y[test_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_x.shape)\n",
    "# print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.where(test_y == 1)[0].shape)\n",
    "# print(np.where(test_y == 0)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(list(set(train_indexes) - set(test_indexes))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(list(set(test_indexes) - set(train_indexes))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_sets(x, y, train_size=1000, seed=1, balanced_test=False):\n",
    "    # Randomly chooses created instances and created balanced train test set.\n",
    "    # If balanced_test==True, it creates balanced test set. \n",
    "    # (If False, takes all remaning data as test.)\n",
    "    random.seed(seed)\n",
    "    one_class_size = int(train_size / 2)\n",
    "    all_one_indexes = np.where(y == 1)[0]\n",
    "    all_zero_indexes = np.where(y == 0)[0]\n",
    "    ones = np.random.choice(all_one_indexes, one_class_size, replace=False)\n",
    "    zeros = np.random.choice(all_zero_indexes, one_class_size, replace=False)\n",
    "    train_indexes = np.concatenate((ones, zeros))\n",
    "    np.random.shuffle(train_indexes)\n",
    "    new_x = x[train_indexes, :, :]\n",
    "    new_y = y[train_indexes, :]\n",
    "    if balanced_test == False:\n",
    "        test_indexes = np.array([i for i in range(len(y)) if i not in train_indexes])\n",
    "        np.random.shuffle(test_indexes)\n",
    "        test_x = x[test_indexes, :, :]\n",
    "        test_y = y[test_indexes, :]\n",
    "    else:\n",
    "        not_used_ones = np.array(list(set(all_one_indexes) - set(ones)))\n",
    "        not_used_zeros = np.array(list(set(all_zero_indexes) - set(zeros)))\n",
    "        test_sample_size = min(len(not_used_ones), len(not_used_zeros))\n",
    "        test_ones = np.random.choice(not_used_ones, test_sample_size, replace=False)\n",
    "        test_zeros = np.random.choice(not_used_zeros, test_sample_size, replace=False)\n",
    "        test_indexes = np.concatenate((test_ones, test_zeros))\n",
    "        np.random.shuffle(test_indexes)\n",
    "        test_x = x[test_indexes, :, :]\n",
    "        test_y = y[test_indexes, :]\n",
    "    return new_x, new_y, test_x, test_y, train_indexes, test_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, train_indexes, test_indexes = create_random_sets(X, y, train_size=1200, seed=53, balanced_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1200, 72, 25)\n",
      "y_train shape: (1200, 1)\n",
      "X_test shape: (266, 72, 25)\n",
      "y_test shape: (266, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_indexes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(train_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(train_indexes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(set(train_indexes) - set(test_indexes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import SGD\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(25, 10, input_length=sequence_length)) # Does not work.\n",
    "model.add(LSTM(32, activation='tanh', dropout=0.2, return_sequences=True, input_shape=(sequence_length, 25))) # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32, activation='tanh', return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32, activation='tanh', return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, activation='tanh', return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, activation='tanh', dropout=0.2))  # return a single vector of dimension 32\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(lr=0.001, \n",
    "             beta_1=0.9, \n",
    "             beta_2=0.999, \n",
    "             epsilon=None, \n",
    "             decay=0.0, \n",
    "             amsgrad=False)\n",
    "\n",
    "# optim = Adagrad(lr=0.01, \n",
    "#                 epsilon=None, \n",
    "#                 decay=0.0)\n",
    "\n",
    "# optim = SGD(lr=0.001, \n",
    "#             decay=1e-6, \n",
    "#             momentum=0.9, \n",
    "#             nesterov=True,\n",
    "#             clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                  min_delta=0.00001, \n",
    "                                  patience=50, \n",
    "                                  verbose=0, \n",
    "                                  mode='auto', \n",
    "                                  baseline=None, \n",
    "                                  restore_best_weights=True),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint('model_weights/weights.{epoch:02d}-{val_acc:.2f}.hdf5',\n",
    "                                    monitor='val_loss', \n",
    "                                    verbose=0, \n",
    "                                    save_best_only=True, \n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', \n",
    "                                    period=1),\n",
    "    \n",
    "    keras.callbacks.TensorBoard(log_dir='model_weights/tensorboard/', \n",
    "                                histogram_freq=0, \n",
    "                                batch_size=32, \n",
    "                                write_graph=True, \n",
    "                                write_grads=False, \n",
    "                                write_images=True, \n",
    "                                embeddings_freq=0, \n",
    "                                embeddings_layer_names=None, \n",
    "                                embeddings_metadata=None, \n",
    "                                embeddings_data=None, \n",
    "                                update_freq='epoch'), \n",
    "    \n",
    "#     keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "#                                       factor=0.2, \n",
    "#                                       patience=10, \n",
    "#                                       min_lr=0.0001), \n",
    "    \n",
    "    keras.callbacks.CSVLogger('model_weights/csv_logger/train_log.csv', separator=',', append=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/500\n",
      "960/960 [==============================] - 2s 2ms/step - loss: 0.6920 - acc: 0.5010 - val_loss: 0.6957 - val_acc: 0.4583\n",
      "Epoch 2/500\n",
      "960/960 [==============================] - 1s 575us/step - loss: 0.6920 - acc: 0.5146 - val_loss: 0.6971 - val_acc: 0.4458\n",
      "Epoch 3/500\n",
      "960/960 [==============================] - 1s 595us/step - loss: 0.6904 - acc: 0.5260 - val_loss: 0.6985 - val_acc: 0.4458\n",
      "Epoch 4/500\n",
      "960/960 [==============================] - 1s 575us/step - loss: 0.6905 - acc: 0.5208 - val_loss: 0.7001 - val_acc: 0.4417\n",
      "Epoch 5/500\n",
      "960/960 [==============================] - 1s 601us/step - loss: 0.6908 - acc: 0.5229 - val_loss: 0.7017 - val_acc: 0.4208\n",
      "Epoch 6/500\n",
      "960/960 [==============================] - 1s 603us/step - loss: 0.6873 - acc: 0.5302 - val_loss: 0.7031 - val_acc: 0.4250\n",
      "Epoch 7/500\n",
      "960/960 [==============================] - 1s 562us/step - loss: 0.6882 - acc: 0.5271 - val_loss: 0.7042 - val_acc: 0.4292\n",
      "Epoch 8/500\n",
      "960/960 [==============================] - 1s 615us/step - loss: 0.6886 - acc: 0.5177 - val_loss: 0.7047 - val_acc: 0.4375\n",
      "Epoch 9/500\n",
      "960/960 [==============================] - 1s 640us/step - loss: 0.6854 - acc: 0.5344 - val_loss: 0.7047 - val_acc: 0.4292\n",
      "Epoch 10/500\n",
      "960/960 [==============================] - 1s 582us/step - loss: 0.6839 - acc: 0.5375 - val_loss: 0.7043 - val_acc: 0.4417\n",
      "Epoch 11/500\n",
      "960/960 [==============================] - 1s 582us/step - loss: 0.6837 - acc: 0.5521 - val_loss: 0.7038 - val_acc: 0.4292\n",
      "Epoch 12/500\n",
      "960/960 [==============================] - 1s 638us/step - loss: 0.6849 - acc: 0.5531 - val_loss: 0.7028 - val_acc: 0.4583\n",
      "Epoch 13/500\n",
      "960/960 [==============================] - 1s 646us/step - loss: 0.6793 - acc: 0.5719 - val_loss: 0.7019 - val_acc: 0.4667\n",
      "Epoch 14/500\n",
      "960/960 [==============================] - 1s 613us/step - loss: 0.6815 - acc: 0.5615 - val_loss: 0.7004 - val_acc: 0.4833\n",
      "Epoch 15/500\n",
      "960/960 [==============================] - 1s 597us/step - loss: 0.6780 - acc: 0.5615 - val_loss: 0.6991 - val_acc: 0.4958\n",
      "Epoch 16/500\n",
      "960/960 [==============================] - 1s 608us/step - loss: 0.6835 - acc: 0.5344 - val_loss: 0.6974 - val_acc: 0.5000\n",
      "Epoch 17/500\n",
      "960/960 [==============================] - 1s 562us/step - loss: 0.6815 - acc: 0.5531 - val_loss: 0.6963 - val_acc: 0.5083\n",
      "Epoch 18/500\n",
      "960/960 [==============================] - 1s 614us/step - loss: 0.6818 - acc: 0.5500 - val_loss: 0.6957 - val_acc: 0.5042\n",
      "Epoch 19/500\n",
      "960/960 [==============================] - 1s 555us/step - loss: 0.6759 - acc: 0.5948 - val_loss: 0.6955 - val_acc: 0.4958\n",
      "Epoch 20/500\n",
      "960/960 [==============================] - 1s 586us/step - loss: 0.6780 - acc: 0.5698 - val_loss: 0.6949 - val_acc: 0.5042\n",
      "Epoch 21/500\n",
      "960/960 [==============================] - 1s 574us/step - loss: 0.6777 - acc: 0.5667 - val_loss: 0.6948 - val_acc: 0.5125\n",
      "Epoch 22/500\n",
      "960/960 [==============================] - 1s 599us/step - loss: 0.6775 - acc: 0.5760 - val_loss: 0.6945 - val_acc: 0.5083\n",
      "Epoch 23/500\n",
      "960/960 [==============================] - 1s 620us/step - loss: 0.6766 - acc: 0.5771 - val_loss: 0.6936 - val_acc: 0.5125\n",
      "Epoch 24/500\n",
      "960/960 [==============================] - 1s 572us/step - loss: 0.6679 - acc: 0.6021 - val_loss: 0.6930 - val_acc: 0.5292\n",
      "Epoch 25/500\n",
      "960/960 [==============================] - 1s 632us/step - loss: 0.6713 - acc: 0.5865 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 26/500\n",
      "960/960 [==============================] - 1s 561us/step - loss: 0.6662 - acc: 0.5906 - val_loss: 0.6888 - val_acc: 0.5625\n",
      "Epoch 27/500\n",
      "960/960 [==============================] - 1s 571us/step - loss: 0.6628 - acc: 0.6021 - val_loss: 0.6861 - val_acc: 0.5667\n",
      "Epoch 28/500\n",
      "960/960 [==============================] - 1s 618us/step - loss: 0.6675 - acc: 0.5906 - val_loss: 0.6846 - val_acc: 0.5625\n",
      "Epoch 29/500\n",
      "960/960 [==============================] - 1s 613us/step - loss: 0.6691 - acc: 0.5750 - val_loss: 0.6843 - val_acc: 0.5625\n",
      "Epoch 30/500\n",
      "960/960 [==============================] - 1s 578us/step - loss: 0.6660 - acc: 0.6031 - val_loss: 0.6848 - val_acc: 0.5542\n",
      "Epoch 31/500\n",
      "960/960 [==============================] - 1s 604us/step - loss: 0.6666 - acc: 0.5958 - val_loss: 0.6864 - val_acc: 0.5667\n",
      "Epoch 32/500\n",
      "960/960 [==============================] - 1s 571us/step - loss: 0.6645 - acc: 0.5990 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 33/500\n",
      "960/960 [==============================] - 1s 603us/step - loss: 0.6632 - acc: 0.6000 - val_loss: 0.6928 - val_acc: 0.5458\n",
      "Epoch 34/500\n",
      "960/960 [==============================] - 1s 612us/step - loss: 0.6567 - acc: 0.5979 - val_loss: 0.6950 - val_acc: 0.5625\n",
      "Epoch 35/500\n",
      "960/960 [==============================] - 1s 597us/step - loss: 0.6556 - acc: 0.5990 - val_loss: 0.6948 - val_acc: 0.5667\n",
      "Epoch 36/500\n",
      "960/960 [==============================] - 1s 594us/step - loss: 0.6616 - acc: 0.6146 - val_loss: 0.6934 - val_acc: 0.5667\n",
      "Epoch 37/500\n",
      "960/960 [==============================] - 1s 568us/step - loss: 0.6516 - acc: 0.6062 - val_loss: 0.6888 - val_acc: 0.5583\n",
      "Epoch 38/500\n",
      "960/960 [==============================] - 1s 592us/step - loss: 0.6610 - acc: 0.6073 - val_loss: 0.6831 - val_acc: 0.5583\n",
      "Epoch 39/500\n",
      "960/960 [==============================] - 1s 616us/step - loss: 0.6560 - acc: 0.6115 - val_loss: 0.6807 - val_acc: 0.5667\n",
      "Epoch 40/500\n",
      "960/960 [==============================] - 1s 616us/step - loss: 0.6470 - acc: 0.6115 - val_loss: 0.6802 - val_acc: 0.5708\n",
      "Epoch 41/500\n",
      "960/960 [==============================] - 1s 577us/step - loss: 0.6476 - acc: 0.6115 - val_loss: 0.6819 - val_acc: 0.5667\n",
      "Epoch 42/500\n",
      "960/960 [==============================] - 1s 591us/step - loss: 0.6604 - acc: 0.5875 - val_loss: 0.6834 - val_acc: 0.5625\n",
      "Epoch 43/500\n",
      "960/960 [==============================] - 1s 612us/step - loss: 0.6572 - acc: 0.6104 - val_loss: 0.6836 - val_acc: 0.5667\n",
      "Epoch 44/500\n",
      "960/960 [==============================] - 1s 589us/step - loss: 0.6487 - acc: 0.6177 - val_loss: 0.6838 - val_acc: 0.5625\n",
      "Epoch 45/500\n",
      "960/960 [==============================] - 1s 632us/step - loss: 0.6481 - acc: 0.6250 - val_loss: 0.6812 - val_acc: 0.5667\n",
      "Epoch 46/500\n",
      "960/960 [==============================] - 1s 617us/step - loss: 0.6543 - acc: 0.6104 - val_loss: 0.6805 - val_acc: 0.5792\n",
      "Epoch 47/500\n",
      "960/960 [==============================] - 1s 623us/step - loss: 0.6492 - acc: 0.6177 - val_loss: 0.6823 - val_acc: 0.5667\n",
      "Epoch 48/500\n",
      "960/960 [==============================] - 1s 617us/step - loss: 0.6410 - acc: 0.6292 - val_loss: 0.6878 - val_acc: 0.5542\n",
      "Epoch 49/500\n",
      "960/960 [==============================] - 1s 673us/step - loss: 0.6505 - acc: 0.6271 - val_loss: 0.6900 - val_acc: 0.5708\n",
      "Epoch 50/500\n",
      "960/960 [==============================] - 1s 621us/step - loss: 0.6446 - acc: 0.6187 - val_loss: 0.6893 - val_acc: 0.5667\n",
      "Epoch 51/500\n",
      "960/960 [==============================] - 1s 623us/step - loss: 0.6435 - acc: 0.6302 - val_loss: 0.6907 - val_acc: 0.5542\n",
      "Epoch 52/500\n",
      "960/960 [==============================] - 1s 622us/step - loss: 0.6419 - acc: 0.6313 - val_loss: 0.6935 - val_acc: 0.5333\n",
      "Epoch 53/500\n",
      "960/960 [==============================] - 1s 615us/step - loss: 0.6375 - acc: 0.6344 - val_loss: 0.6954 - val_acc: 0.5458\n",
      "Epoch 54/500\n",
      "960/960 [==============================] - 1s 548us/step - loss: 0.6360 - acc: 0.6375 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 55/500\n",
      "960/960 [==============================] - 1s 616us/step - loss: 0.6329 - acc: 0.6167 - val_loss: 0.6887 - val_acc: 0.5667\n",
      "Epoch 56/500\n",
      "960/960 [==============================] - 1s 554us/step - loss: 0.6265 - acc: 0.6375 - val_loss: 0.6828 - val_acc: 0.5792\n",
      "Epoch 57/500\n",
      "960/960 [==============================] - 0s 507us/step - loss: 0.6349 - acc: 0.6469 - val_loss: 0.6809 - val_acc: 0.5583\n",
      "Epoch 58/500\n",
      "960/960 [==============================] - 1s 534us/step - loss: 0.6405 - acc: 0.6177 - val_loss: 0.6835 - val_acc: 0.5458\n",
      "Epoch 59/500\n",
      "960/960 [==============================] - 1s 619us/step - loss: 0.6376 - acc: 0.6354 - val_loss: 0.6922 - val_acc: 0.5667\n",
      "Epoch 60/500\n",
      "960/960 [==============================] - 1s 668us/step - loss: 0.6378 - acc: 0.6313 - val_loss: 0.6941 - val_acc: 0.5667\n",
      "Epoch 61/500\n",
      "960/960 [==============================] - 1s 593us/step - loss: 0.6284 - acc: 0.6417 - val_loss: 0.6903 - val_acc: 0.5583\n",
      "Epoch 62/500\n",
      "960/960 [==============================] - 1s 574us/step - loss: 0.6312 - acc: 0.6323 - val_loss: 0.6842 - val_acc: 0.5542\n",
      "Epoch 63/500\n",
      "960/960 [==============================] - 1s 596us/step - loss: 0.6354 - acc: 0.6417 - val_loss: 0.6828 - val_acc: 0.5542\n",
      "Epoch 64/500\n",
      "960/960 [==============================] - 1s 608us/step - loss: 0.6412 - acc: 0.6177 - val_loss: 0.6860 - val_acc: 0.5583\n",
      "Epoch 65/500\n",
      "960/960 [==============================] - 1s 598us/step - loss: 0.6233 - acc: 0.6365 - val_loss: 0.6984 - val_acc: 0.5583\n",
      "Epoch 66/500\n",
      "960/960 [==============================] - 1s 613us/step - loss: 0.6273 - acc: 0.6396 - val_loss: 0.7083 - val_acc: 0.5458\n",
      "Epoch 67/500\n",
      "960/960 [==============================] - 1s 572us/step - loss: 0.6290 - acc: 0.6375 - val_loss: 0.7015 - val_acc: 0.5625\n",
      "Epoch 68/500\n",
      "960/960 [==============================] - 1s 609us/step - loss: 0.6316 - acc: 0.6458 - val_loss: 0.6929 - val_acc: 0.5667\n",
      "Epoch 69/500\n",
      "960/960 [==============================] - 1s 667us/step - loss: 0.6215 - acc: 0.6573 - val_loss: 0.6885 - val_acc: 0.5792\n",
      "Epoch 70/500\n",
      "960/960 [==============================] - 1s 611us/step - loss: 0.6148 - acc: 0.6677 - val_loss: 0.6943 - val_acc: 0.5667\n",
      "Epoch 71/500\n",
      "960/960 [==============================] - 1s 603us/step - loss: 0.6118 - acc: 0.6677 - val_loss: 0.7007 - val_acc: 0.5708\n",
      "Epoch 72/500\n",
      "960/960 [==============================] - 1s 568us/step - loss: 0.6266 - acc: 0.6448 - val_loss: 0.7070 - val_acc: 0.5750\n",
      "Epoch 73/500\n",
      "960/960 [==============================] - 1s 608us/step - loss: 0.6203 - acc: 0.6594 - val_loss: 0.7101 - val_acc: 0.5708\n",
      "Epoch 74/500\n",
      "960/960 [==============================] - 1s 613us/step - loss: 0.6420 - acc: 0.6354 - val_loss: 0.7088 - val_acc: 0.5583\n",
      "Epoch 75/500\n",
      "960/960 [==============================] - 1s 624us/step - loss: 0.6210 - acc: 0.6490 - val_loss: 0.7014 - val_acc: 0.5500\n",
      "Epoch 76/500\n",
      "960/960 [==============================] - 1s 561us/step - loss: 0.6260 - acc: 0.6458 - val_loss: 0.7017 - val_acc: 0.5458\n",
      "Epoch 77/500\n",
      "960/960 [==============================] - 1s 597us/step - loss: 0.6276 - acc: 0.6406 - val_loss: 0.7048 - val_acc: 0.5500\n",
      "Epoch 78/500\n",
      "960/960 [==============================] - 1s 616us/step - loss: 0.6225 - acc: 0.6323 - val_loss: 0.7096 - val_acc: 0.5708\n",
      "Epoch 79/500\n",
      "960/960 [==============================] - 1s 633us/step - loss: 0.6219 - acc: 0.6396 - val_loss: 0.7025 - val_acc: 0.5667\n",
      "Epoch 80/500\n",
      "960/960 [==============================] - 1s 713us/step - loss: 0.6120 - acc: 0.6552 - val_loss: 0.6964 - val_acc: 0.5708\n",
      "Epoch 81/500\n",
      "960/960 [==============================] - 1s 657us/step - loss: 0.6182 - acc: 0.6396 - val_loss: 0.6938 - val_acc: 0.5625\n",
      "Epoch 82/500\n",
      "960/960 [==============================] - 1s 612us/step - loss: 0.6102 - acc: 0.6562 - val_loss: 0.6957 - val_acc: 0.5667\n",
      "Epoch 83/500\n",
      "960/960 [==============================] - 1s 623us/step - loss: 0.6142 - acc: 0.6448 - val_loss: 0.7046 - val_acc: 0.5542\n",
      "Epoch 84/500\n",
      "960/960 [==============================] - 1s 591us/step - loss: 0.6116 - acc: 0.6615 - val_loss: 0.7129 - val_acc: 0.5458\n",
      "Epoch 85/500\n",
      "960/960 [==============================] - 1s 538us/step - loss: 0.6082 - acc: 0.6698 - val_loss: 0.7124 - val_acc: 0.5458\n",
      "Epoch 86/500\n",
      "960/960 [==============================] - 1s 602us/step - loss: 0.6180 - acc: 0.6490 - val_loss: 0.7075 - val_acc: 0.5583\n",
      "Epoch 87/500\n",
      "960/960 [==============================] - 1s 598us/step - loss: 0.6170 - acc: 0.6521 - val_loss: 0.7047 - val_acc: 0.5667\n",
      "Epoch 88/500\n",
      "960/960 [==============================] - 1s 582us/step - loss: 0.6091 - acc: 0.6687 - val_loss: 0.7019 - val_acc: 0.5667\n",
      "Epoch 89/500\n",
      "960/960 [==============================] - 1s 667us/step - loss: 0.6036 - acc: 0.6646 - val_loss: 0.7048 - val_acc: 0.5542\n",
      "Epoch 90/500\n",
      "960/960 [==============================] - 1s 577us/step - loss: 0.6092 - acc: 0.6635 - val_loss: 0.7113 - val_acc: 0.5542\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train, y_train, batch_size=X_train.shape[0], epochs=500, validation_split=0.2, shuffle=False, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6744316278543687, 0.5864661649653786]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.6926618218421936,\n",
       "  0.6919943690299988,\n",
       "  0.6915327310562134,\n",
       "  0.6910162568092346,\n",
       "  0.6906114816665649,\n",
       "  0.690345048904419,\n",
       "  0.6902182698249817,\n",
       "  0.6900853514671326,\n",
       "  0.6900063753128052,\n",
       "  0.689851701259613,\n",
       "  0.6895632147789001,\n",
       "  0.6892606616020203,\n",
       "  0.688995361328125,\n",
       "  0.6887547969818115,\n",
       "  0.6885337233543396,\n",
       "  0.6884459257125854,\n",
       "  0.6884072422981262,\n",
       "  0.6885127425193787,\n",
       "  0.6884085536003113,\n",
       "  0.6885955333709717,\n",
       "  0.6891963481903076,\n",
       "  0.6896704435348511,\n",
       "  0.6900292634963989],\n",
       " 'val_acc': [0.512499988079071,\n",
       "  0.5083333253860474,\n",
       "  0.5583333373069763,\n",
       "  0.5249999761581421,\n",
       "  0.5208333134651184,\n",
       "  0.5166666507720947,\n",
       "  0.5458333492279053,\n",
       "  0.550000011920929,\n",
       "  0.550000011920929,\n",
       "  0.5458333492279053,\n",
       "  0.5583333373069763,\n",
       "  0.550000011920929,\n",
       "  0.5375000238418579,\n",
       "  0.5291666388511658,\n",
       "  0.5249999761581421,\n",
       "  0.5166666507720947,\n",
       "  0.5,\n",
       "  0.4958333373069763,\n",
       "  0.5083333253860474,\n",
       "  0.5166666507720947,\n",
       "  0.5208333134651184,\n",
       "  0.5166666507720947,\n",
       "  0.5249999761581421],\n",
       " 'loss': [0.6930906176567078,\n",
       "  0.6917495727539062,\n",
       "  0.6911013126373291,\n",
       "  0.6899125576019287,\n",
       "  0.6898171901702881,\n",
       "  0.690518319606781,\n",
       "  0.6892668604850769,\n",
       "  0.6872464418411255,\n",
       "  0.6865412592887878,\n",
       "  0.6857152581214905,\n",
       "  0.6848734021186829,\n",
       "  0.6819332242012024,\n",
       "  0.6835604906082153,\n",
       "  0.679645836353302,\n",
       "  0.6802801489830017,\n",
       "  0.6783047914505005,\n",
       "  0.6780889630317688,\n",
       "  0.6740153431892395,\n",
       "  0.6741148829460144,\n",
       "  0.6706331968307495,\n",
       "  0.6713292002677917,\n",
       "  0.6655743718147278,\n",
       "  0.6708847284317017],\n",
       " 'acc': [0.5052083134651184,\n",
       "  0.5104166865348816,\n",
       "  0.5354166626930237,\n",
       "  0.5572916865348816,\n",
       "  0.5416666865348816,\n",
       "  0.546875,\n",
       "  0.5572916865348816,\n",
       "  0.5354166626930237,\n",
       "  0.5854166746139526,\n",
       "  0.5791666507720947,\n",
       "  0.5697916746139526,\n",
       "  0.5770833492279053,\n",
       "  0.5802083611488342,\n",
       "  0.578125,\n",
       "  0.59375,\n",
       "  0.5708333253860474,\n",
       "  0.5822916626930237,\n",
       "  0.5822916626930237,\n",
       "  0.5791666507720947,\n",
       "  0.59375,\n",
       "  0.5697916746139526,\n",
       "  0.5854166746139526,\n",
       "  0.581250011920929]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49000001, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.54000002, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.47      , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.54000002, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.54000002, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.46000001, 0.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.47      , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47      , 0.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.54000002, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.47      , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.47      , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.46000001, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.46000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.46000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.47      , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.55000001, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.54000002, 0.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.41999999, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.51999998, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.50999999, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.51999998, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.52999997, 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.46000001, 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.47999999, 0.        ],\n",
       "       [0.5       , 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.44999999, 0.        ],\n",
       "       [0.52999997, 1.        ],\n",
       "       [0.49000001, 0.        ],\n",
       "       [0.46000001, 0.        ],\n",
       "       [0.5       , 0.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.50999999, 1.        ],\n",
       "       [0.49000001, 1.        ],\n",
       "       [0.47999999, 1.        ],\n",
       "       [0.52999997, 1.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.around(model.predict(X_test), decimals=2), y_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(sequence_length, 25)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "Epoch 1/100\n",
      "960/960 [==============================] - 1s 1ms/step - loss: 0.6927 - acc: 0.5115 - val_loss: 0.6888 - val_acc: 0.5292\n",
      "Epoch 2/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6895 - acc: 0.5354 - val_loss: 0.6819 - val_acc: 0.5458\n",
      "Epoch 3/100\n",
      "960/960 [==============================] - 0s 28us/step - loss: 0.6876 - acc: 0.5521 - val_loss: 0.6850 - val_acc: 0.5167\n",
      "Epoch 4/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6867 - acc: 0.5521 - val_loss: 0.7160 - val_acc: 0.4958\n",
      "Epoch 5/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.7280 - acc: 0.5010 - val_loss: 0.6809 - val_acc: 0.5458\n",
      "Epoch 6/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6809 - acc: 0.5656 - val_loss: 0.6773 - val_acc: 0.5542\n",
      "Epoch 7/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6797 - acc: 0.5615 - val_loss: 0.6752 - val_acc: 0.5583\n",
      "Epoch 8/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6774 - acc: 0.5615 - val_loss: 0.6735 - val_acc: 0.5708\n",
      "Epoch 9/100\n",
      "960/960 [==============================] - 0s 29us/step - loss: 0.6762 - acc: 0.5646 - val_loss: 0.6718 - val_acc: 0.5625\n",
      "Epoch 10/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6715 - acc: 0.5844 - val_loss: 0.6721 - val_acc: 0.5708\n",
      "Epoch 11/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6735 - acc: 0.5865 - val_loss: 0.6758 - val_acc: 0.5708\n",
      "Epoch 12/100\n",
      "960/960 [==============================] - 0s 28us/step - loss: 0.6782 - acc: 0.5552 - val_loss: 0.6822 - val_acc: 0.5375\n",
      "Epoch 13/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6782 - acc: 0.5781 - val_loss: 0.6798 - val_acc: 0.5542\n",
      "Epoch 14/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6818 - acc: 0.5531 - val_loss: 0.6707 - val_acc: 0.5583\n",
      "Epoch 15/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6681 - acc: 0.5896 - val_loss: 0.6692 - val_acc: 0.5667\n",
      "Epoch 16/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6650 - acc: 0.6000 - val_loss: 0.6678 - val_acc: 0.5750\n",
      "Epoch 17/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6621 - acc: 0.5906 - val_loss: 0.6690 - val_acc: 0.5792\n",
      "Epoch 18/100\n",
      "960/960 [==============================] - 0s 34us/step - loss: 0.6586 - acc: 0.5969 - val_loss: 0.6696 - val_acc: 0.5625\n",
      "Epoch 19/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6603 - acc: 0.5948 - val_loss: 0.7148 - val_acc: 0.5292\n",
      "Epoch 20/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6988 - acc: 0.5656 - val_loss: 0.6964 - val_acc: 0.5208\n",
      "Epoch 21/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6962 - acc: 0.5333 - val_loss: 0.6694 - val_acc: 0.5583\n",
      "Epoch 22/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6594 - acc: 0.6021 - val_loss: 0.6680 - val_acc: 0.5667\n",
      "Epoch 23/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6596 - acc: 0.6115 - val_loss: 0.6672 - val_acc: 0.5625\n",
      "Epoch 24/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6574 - acc: 0.6229 - val_loss: 0.6666 - val_acc: 0.5625\n",
      "Epoch 25/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6543 - acc: 0.6052 - val_loss: 0.6666 - val_acc: 0.5625\n",
      "Epoch 26/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6491 - acc: 0.6198 - val_loss: 0.6661 - val_acc: 0.5750\n",
      "Epoch 27/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6479 - acc: 0.6187 - val_loss: 0.6663 - val_acc: 0.5833\n",
      "Epoch 28/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6444 - acc: 0.6250 - val_loss: 0.6652 - val_acc: 0.5917\n",
      "Epoch 29/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6445 - acc: 0.6146 - val_loss: 0.6745 - val_acc: 0.5833\n",
      "Epoch 30/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6474 - acc: 0.6250 - val_loss: 0.7284 - val_acc: 0.5167\n",
      "Epoch 31/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.7206 - acc: 0.5302 - val_loss: 0.7089 - val_acc: 0.5375\n",
      "Epoch 32/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6794 - acc: 0.5875 - val_loss: 0.6706 - val_acc: 0.5667\n",
      "Epoch 33/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6586 - acc: 0.5896 - val_loss: 0.6664 - val_acc: 0.5875\n",
      "Epoch 34/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6447 - acc: 0.6281 - val_loss: 0.6655 - val_acc: 0.5958\n",
      "Epoch 35/100\n",
      "960/960 [==============================] - 0s 29us/step - loss: 0.6436 - acc: 0.6198 - val_loss: 0.6649 - val_acc: 0.5958\n",
      "Epoch 36/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6397 - acc: 0.6354 - val_loss: 0.6648 - val_acc: 0.5917\n",
      "Epoch 37/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6350 - acc: 0.6313 - val_loss: 0.6650 - val_acc: 0.5917\n",
      "Epoch 38/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6355 - acc: 0.6250 - val_loss: 0.6638 - val_acc: 0.5958\n",
      "Epoch 39/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6283 - acc: 0.6365 - val_loss: 0.6679 - val_acc: 0.5917\n",
      "Epoch 40/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6317 - acc: 0.6333 - val_loss: 0.6760 - val_acc: 0.5542\n",
      "Epoch 41/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6407 - acc: 0.6115 - val_loss: 0.7550 - val_acc: 0.5083\n",
      "Epoch 42/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.7158 - acc: 0.5781 - val_loss: 0.7046 - val_acc: 0.5208\n",
      "Epoch 43/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6823 - acc: 0.5521 - val_loss: 0.6669 - val_acc: 0.5833\n",
      "Epoch 44/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6376 - acc: 0.6302 - val_loss: 0.6635 - val_acc: 0.5917\n",
      "Epoch 45/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6339 - acc: 0.6385 - val_loss: 0.6633 - val_acc: 0.6083\n",
      "Epoch 46/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6290 - acc: 0.6396 - val_loss: 0.6629 - val_acc: 0.6042\n",
      "Epoch 47/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6273 - acc: 0.6406 - val_loss: 0.6632 - val_acc: 0.6083\n",
      "Epoch 48/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6228 - acc: 0.6375 - val_loss: 0.6629 - val_acc: 0.6000\n",
      "Epoch 49/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6225 - acc: 0.6344 - val_loss: 0.6640 - val_acc: 0.6125\n",
      "Epoch 50/100\n",
      "960/960 [==============================] - 0s 29us/step - loss: 0.6202 - acc: 0.6344 - val_loss: 0.6652 - val_acc: 0.5792\n",
      "Epoch 51/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6184 - acc: 0.6448 - val_loss: 0.6810 - val_acc: 0.5750\n",
      "Epoch 52/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6311 - acc: 0.6292 - val_loss: 0.7332 - val_acc: 0.5292\n",
      "Epoch 53/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.7040 - acc: 0.5583 - val_loss: 0.7282 - val_acc: 0.5250\n",
      "Epoch 54/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6860 - acc: 0.5938 - val_loss: 0.6670 - val_acc: 0.5667\n",
      "Epoch 55/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6336 - acc: 0.6240 - val_loss: 0.6614 - val_acc: 0.6125\n",
      "Epoch 56/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6255 - acc: 0.6490 - val_loss: 0.6609 - val_acc: 0.6125\n",
      "Epoch 57/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6215 - acc: 0.6479 - val_loss: 0.6614 - val_acc: 0.6167\n",
      "Epoch 58/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6159 - acc: 0.6490 - val_loss: 0.6613 - val_acc: 0.6000\n",
      "Epoch 59/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6144 - acc: 0.6500 - val_loss: 0.6630 - val_acc: 0.6125\n",
      "Epoch 60/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6130 - acc: 0.6562 - val_loss: 0.6626 - val_acc: 0.5875\n",
      "Epoch 61/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6105 - acc: 0.6510 - val_loss: 0.6719 - val_acc: 0.5583\n",
      "Epoch 62/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6141 - acc: 0.6469 - val_loss: 0.6926 - val_acc: 0.5458\n",
      "Epoch 63/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6462 - acc: 0.5969 - val_loss: 0.7662 - val_acc: 0.5292\n",
      "Epoch 64/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.7162 - acc: 0.5760 - val_loss: 0.6855 - val_acc: 0.5417\n",
      "Epoch 65/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6471 - acc: 0.5875 - val_loss: 0.6648 - val_acc: 0.5833\n",
      "Epoch 66/100\n",
      "960/960 [==============================] - 0s 28us/step - loss: 0.6192 - acc: 0.6521 - val_loss: 0.6610 - val_acc: 0.6042\n",
      "Epoch 67/100\n",
      "960/960 [==============================] - 0s 28us/step - loss: 0.6120 - acc: 0.6667 - val_loss: 0.6616 - val_acc: 0.6208\n",
      "Epoch 68/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6074 - acc: 0.6604 - val_loss: 0.6617 - val_acc: 0.6208\n",
      "Epoch 69/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6046 - acc: 0.6656 - val_loss: 0.6627 - val_acc: 0.6083\n",
      "Epoch 70/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6027 - acc: 0.6615 - val_loss: 0.6646 - val_acc: 0.6125\n",
      "Epoch 71/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6005 - acc: 0.6583 - val_loss: 0.6684 - val_acc: 0.5750\n",
      "Epoch 72/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6017 - acc: 0.6656 - val_loss: 0.6900 - val_acc: 0.5667\n",
      "Epoch 73/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6186 - acc: 0.6562 - val_loss: 0.7664 - val_acc: 0.5208\n",
      "Epoch 74/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.7141 - acc: 0.5625 - val_loss: 0.7406 - val_acc: 0.5292\n",
      "Epoch 75/100\n",
      "960/960 [==============================] - 0s 34us/step - loss: 0.6852 - acc: 0.5927 - val_loss: 0.6648 - val_acc: 0.5625\n",
      "Epoch 76/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6126 - acc: 0.6521 - val_loss: 0.6608 - val_acc: 0.6125\n",
      "Epoch 77/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.6003 - acc: 0.6729 - val_loss: 0.6605 - val_acc: 0.6083\n",
      "Epoch 78/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6000 - acc: 0.6646 - val_loss: 0.6615 - val_acc: 0.6167\n",
      "Epoch 79/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.5976 - acc: 0.6760 - val_loss: 0.6627 - val_acc: 0.6250\n",
      "Epoch 80/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.5965 - acc: 0.6646 - val_loss: 0.6640 - val_acc: 0.6167\n",
      "Epoch 81/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.5866 - acc: 0.6812 - val_loss: 0.6658 - val_acc: 0.6083\n",
      "Epoch 82/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.5872 - acc: 0.6844 - val_loss: 0.6687 - val_acc: 0.6000\n",
      "Epoch 83/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.5850 - acc: 0.6719 - val_loss: 0.6748 - val_acc: 0.5708\n",
      "Epoch 84/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.5884 - acc: 0.6708 - val_loss: 0.7030 - val_acc: 0.5583\n",
      "Epoch 85/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6179 - acc: 0.6125 - val_loss: 0.8494 - val_acc: 0.5250\n",
      "Epoch 86/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.7723 - acc: 0.5552 - val_loss: 0.7165 - val_acc: 0.5375\n",
      "Epoch 87/100\n",
      "960/960 [==============================] - 0s 33us/step - loss: 0.6583 - acc: 0.5854 - val_loss: 0.6748 - val_acc: 0.5625\n",
      "Epoch 88/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.6054 - acc: 0.6625 - val_loss: 0.6612 - val_acc: 0.5958\n",
      "Epoch 89/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.5917 - acc: 0.6771 - val_loss: 0.6618 - val_acc: 0.6167\n",
      "Epoch 90/100\n",
      "960/960 [==============================] - 0s 32us/step - loss: 0.5900 - acc: 0.6802 - val_loss: 0.6626 - val_acc: 0.6167\n",
      "Epoch 91/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.5828 - acc: 0.6885 - val_loss: 0.6642 - val_acc: 0.6125\n",
      "Epoch 92/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.5790 - acc: 0.6906 - val_loss: 0.6667 - val_acc: 0.6167\n",
      "Epoch 93/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.5790 - acc: 0.6896 - val_loss: 0.6692 - val_acc: 0.6042\n",
      "Epoch 94/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.5763 - acc: 0.7052 - val_loss: 0.6702 - val_acc: 0.6042\n",
      "Epoch 95/100\n",
      "960/960 [==============================] - 0s 29us/step - loss: 0.5713 - acc: 0.7042 - val_loss: 0.6752 - val_acc: 0.5833\n",
      "Epoch 96/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.5758 - acc: 0.6969 - val_loss: 0.7092 - val_acc: 0.5708\n",
      "Epoch 97/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6069 - acc: 0.6302 - val_loss: 0.8715 - val_acc: 0.5167\n",
      "Epoch 98/100\n",
      "960/960 [==============================] - 0s 31us/step - loss: 0.7896 - acc: 0.5521 - val_loss: 0.7129 - val_acc: 0.5417\n",
      "Epoch 99/100\n",
      "960/960 [==============================] - 0s 30us/step - loss: 0.6345 - acc: 0.6042 - val_loss: 0.6791 - val_acc: 0.5625\n",
      "266/266 [==============================] - 0s 217us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=X_train.shape[0], epochs=100, validation_split=0.2, shuffle=True, callbacks=my_callbacks)\n",
    "# model.fit(X_train, y_train, batch_size=16, epochs=50)\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6989397124240273, 0.548872180899283]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
